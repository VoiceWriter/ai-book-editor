#!/usr/bin/env python3
"""
Provide AI editorial review on pull requests.

This script:
1. Reads the PR diff and changed files
2. Loads full chapter content for context
3. Calls Claude for editorial review
4. Posts review as PR review (not just comment)
"""

import os
import sys

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from scripts.utils.github_client import (  # noqa: E402
    get_github_client,
    get_pull_request,
    get_repo,
    read_file_content,
)
from scripts.utils.knowledge_base import load_editorial_context  # noqa: E402
from scripts.utils.llm_client import (  # noqa: E402
    build_editorial_prompt,
    call_editorial,
)


def get_pr_files_content(repo, pr) -> list:
    """Get content of changed files in the PR."""
    files = []
    for f in pr.get_files():
        if f.filename.startswith("chapters/") and f.filename.endswith(".md"):
            # Get the new content from the PR branch
            content = read_file_content(repo, f.filename, ref=pr.head.sha)

            # Get the old content from base branch for comparison
            old_content = read_file_content(repo, f.filename, ref=pr.base.sha)

            files.append(
                {
                    "filename": f.filename,
                    "status": f.status,  # added, modified, removed
                    "patch": f.patch,  # The diff
                    "new_content": content,
                    "old_content": old_content,
                    "additions": f.additions,
                    "deletions": f.deletions,
                }
            )
    return files


def main():
    pr_number = int(os.environ.get("PR_NUMBER", 0))
    if not pr_number:
        print("ERROR: PR_NUMBER not set")
        sys.exit(1)

    gh = get_github_client()
    repo = get_repo(gh)
    pr = get_pull_request(repo, pr_number)

    # Get changed files
    changed_files = get_pr_files_content(repo, pr)

    if not changed_files:
        print("No chapter files changed, skipping review.")
        sys.exit(0)

    # Load editorial context
    context = load_editorial_context(repo)

    # Build review prompt
    files_summary = []
    for f in changed_files:
        files_summary.append(
            f"""
### File: {f['filename']}
**Status:** {f['status']} (+{f['additions']} -{f['deletions']})

**Changes (diff):**
```diff
{f['patch'][:2000] if f['patch'] else 'No diff available'}
```

**Full new content:**
{f['new_content'][:3000] if f['new_content'] else 'File deleted'}
"""
        )

    task = f"""Review this pull request for editorial quality.

**PR Title:** {pr.title}
**PR Description:**
{pr.body or 'No description provided'}

**Changed Files:**
{''.join(files_summary)}

Provide editorial feedback following these guidelines:

1. **What's Working Well** - Start positive. What's effective about these changes?

2. **Structural Feedback** - Does this fit well in the book's flow? Any organization issues?

3. **Line-Level Suggestions** - Specific improvements to prose, clarity, or style.
   Format as: `Line/section: "original text" -> "suggested text" (reason)`

4. **Style Guide Compliance** - Any violations of the editorial guidelines?

5. **Questions for Author** - Anything unclear that needs clarification?

6. **Overall Assessment** - APPROVE, REQUEST_CHANGES, or COMMENT?
   - APPROVE: Good to merge as-is or with minor optional tweaks
   - REQUEST_CHANGES: Needs work before merging
   - COMMENT: Observations only, author decides

Remember: You work FOR the author. Enhance their voice, don't replace it."""

    prompt = build_editorial_prompt(
        persona=context["persona"],
        guidelines=context["guidelines"],
        glossary=context["glossary"],
        knowledge_base=context["knowledge_formatted"],
        chapter_list=context["chapters"],
        task=task,
        content="",  # Content is in the task
    )

    # Call LLM with reasoning enabled
    print("Calling LLM for PR review (with reasoning)...")
    llm_response = call_editorial(prompt, max_tokens=8000)
    print(f"LLM call complete: {llm_response.usage.format_compact()}")
    if llm_response.has_reasoning():
        print("Editorial reasoning captured for transparency")

    # Determine review action
    review_action = "COMMENT"  # Default
    response_lower = llm_response.content.lower()
    if "overall assessment" in response_lower:
        if "approve" in response_lower.split("overall assessment")[-1][:100]:
            review_action = "APPROVE"
        elif "request_changes" in response_lower.split("overall assessment")[-1][:100]:
            review_action = "REQUEST_CHANGES"

    # Format reasoning section
    reasoning_section = llm_response.format_editorial_explanation()

    # Post as PR review
    review_body = f"""## AI Editorial Review

{llm_response.content}

{reasoning_section}

---
*This review was generated by AI Book Editor. Take what's useful, ignore what isn't.*

<sub>{llm_response.usage.format_summary()}</sub>
"""

    pr.create_review(body=review_body, event=review_action)
    print(f"Posted {review_action} review on PR #{pr_number}")


if __name__ == "__main__":
    main()
